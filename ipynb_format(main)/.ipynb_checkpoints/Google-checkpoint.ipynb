{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suffering-testimony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T11:31:22.857914Z",
     "start_time": "2021-03-24T11:31:22.855914Z"
    }
   },
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208eed3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T10:36:00.676287Z",
     "start_time": "2021-05-08T10:33:55.448262Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Search_Tag : cat\n",
      "Input scroll_cnt(minimim:5) : 7\n",
      "Input scroll_sleep_second >>> range(5~10) : 3\n",
      "\n",
      "Overlaped srcs :  2300\n",
      "Non_Overlap srcs :  500\n"
     ]
    }
   ],
   "source": [
    "### Google\n",
    "\"\"\"Before execute code below, check out your kernel or jupyter notebook kernel environment \n",
    "If you have problem, just copy this code and paste to yout jupyter notebook (recommended)\n",
    "Also, before execute this page, execute this first >> \"Get Chrome driver & dir setting.ipynb\"\n",
    "\n",
    "browser must be pop up on the screen : if the browser is in a state of minimization, results may go bad\n",
    "(It does not matter covering the page with other page like jupyternotebook >> you can do other works)\n",
    "\n",
    "If you have trouble with lxml, selenium, bs4, try to isntall module in anaconda prompt\n",
    ">>> execute anconda prompt, try to [conda install lxml], [conda install selenium], [conda install bs4]\n",
    "\n",
    "warning : If you try this code with high frequency, Search engine may ban your ip temporarily (for 5~10 minutes)\n",
    "\n",
    "Refer to : Scroll_cnt=5 >>> about 300~400 imgs (depending on the searching word)\"\"\"\n",
    "\n",
    "\n",
    "## Install module required\n",
    "#!pip install lxml\n",
    "#!pip install selenium\n",
    "#!pip install bs4\n",
    "\n",
    "\n",
    "## Import modules\n",
    "import urllib.request    \n",
    "from bs4 import BeautifulSoup    \n",
    "from selenium import webdriver    \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time    \n",
    "\n",
    "\n",
    "##### Path ######################################################################\n",
    "Chromedriver_PATH = 'c:\\\\chrome_webdriver\\\\chromedriver.exe'  # Chromedriver PATH \n",
    "save_path = 'd:\\\\images\\\\google\\\\'  #save_path \n",
    "#################################################################################\n",
    "\n",
    "\n",
    "## get userdata & parameters\n",
    "Search_Tag = input(\"Input Search_Tag : \")  # Search_Tag\n",
    "scroll_cnt = int(input(\"Input scroll_cnt(minimim:5) : \"))  #scroll count\n",
    "scrolltime = float(input(\"Input scroll_sleep_second >>> range(5~10) : \"))  #Sleep time \n",
    "\n",
    "\n",
    "## Get driver & open\n",
    "driver = webdriver.Chrome(Chromedriver_PATH)  # Chromedriver PATH \n",
    "driver.get(\"https:\\\\www.google.co.kr\\imghp?hl=ko&tab=wi&ei=l1AdWbegOcra8QXvtr-4Cw&ved=0EKouCBUoAQ\")    \n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "## input Search_Tag & Submit\n",
    "elem = driver.find_element_by_xpath(\"//*[@class='gLFyf gsfi']\") \n",
    "elem.send_keys(Search_Tag)\n",
    "time.sleep(1.5)  #Do not remove >> if you remove this line, can't go next step \n",
    "elem.submit()\n",
    "time.sleep(3.0)  #Do not remove\n",
    "\n",
    "############## Functions ################################################################################\n",
    "def fetch_list_url():  #parsing src url\n",
    "    imgList = soup.find_all(\"img\", class_=\"rg_i Q4LuWd\")\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])                   \n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "\n",
    "\n",
    "def fetch_detail_url():  #save src to local  #changing save_path : Go to the top of this page (Path)\n",
    "    for idx,p in enumerate(params,1):  #enumerate idx option 1 : get start index from 1 (default=0)\n",
    "        urllib.request.urlretrieve(p, save_path + Search_Tag + '_' + str(idx) + \"_google\" + \".jpg\")\n",
    "###########################################################################################################    \n",
    "\n",
    "\n",
    "## Scrolling & Parsing\n",
    "params=[]\n",
    "for i in range(5):\n",
    "    html = driver.page_source  #get source         \n",
    "    soup = BeautifulSoup(html, \"lxml\") \n",
    "    params = fetch_list_url()  #save the img_url to params\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  #scroll\n",
    "    time.sleep(scrolltime)\n",
    "\n",
    "\n",
    "## Addtitional scrolling ('more results')\n",
    "if scroll_cnt > 5:\n",
    "    try : \n",
    "        driver.find_element_by_xpath(\"//*[@class='mye4qd']\").click()  #click 'more results'\n",
    "        for i in range(scroll_cnt-5):\n",
    "            html = driver.page_source  #get source         \n",
    "            soup = BeautifulSoup(html, \"lxml\") \n",
    "            params = fetch_list_url()  #save the img_url to params\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  #scroll\n",
    "            time.sleep(scrolltime)\n",
    "    except :\n",
    "        print(\"Results are too short than requested scroll_cnt\")\n",
    "        \n",
    "    \n",
    "## Save imgs\n",
    "print('')\n",
    "print(\"Overlaped srcs : \", len(params))\n",
    "params=list(dict.fromkeys(params))  #delete overlap  #index URL >> https://m31phy.tistory.com/130\n",
    "fetch_detail_url()  #save img\n",
    "print(\"Non_Overlap srcs : \", len(params))\n",
    "\n",
    "\n",
    "driver.close()  #close browser 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ob_1",
   "language": "python",
   "name": "ob_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
