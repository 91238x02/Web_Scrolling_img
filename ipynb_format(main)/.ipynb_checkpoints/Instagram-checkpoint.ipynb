{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confused-desire",
   "metadata": {},
   "source": [
    "### Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alone-vinyl",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T11:14:34.802952Z",
     "start_time": "2021-05-08T11:13:33.715920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID : icevreamn2@gmail.com\n",
      "Input PWD : ········\n",
      "Input HashTag # : cat\n",
      "Input scroll_cnt : 2\n",
      "Input scroll_sleep_second >>> range(5~10) : 1\n",
      "\n",
      "Overlap srcs :  78\n",
      "Non_Overlap srcs :  45\n"
     ]
    }
   ],
   "source": [
    "### Instagram scrolling \n",
    "\"\"\"Before execute code below, check out your kernel or jupyter notebook kernel environment \n",
    "If you have problem, just copy this code and paste to yout jupyter notebook (recommended)\n",
    "Also, before execute this page, execute this first >> \"Get Chrome driver & dir setting.ipynb\"\n",
    "\n",
    "This code find first pop up tag list : when you enter the tag like \"#apple\", code chooses the first recommanded tag\n",
    "So, before execute the code, check out what is the first pop up tag for accurate img scrolling.\n",
    "And browser must be pop up on the screen : if the browser is in a state of minimization, results may go bad\n",
    "(It does not matter covering the instagram page with other page like jupyternotebook >> you can do other works)\n",
    "\n",
    "If you have trouble with lxml, selenium, bs4, try to isntall module in anaconda prompt\n",
    ">>> execute anconda prompt, try to [conda install lxml], [conda install selenium], [conda install bs4]\n",
    "\n",
    "Also, this code has a bug that local pc's wallpapers is changed to one of scrolled imgs. \n",
    "(I don't know why the bug occurs. I guess \"params.append(im[\"srcset\"])\" in line 74 is the causation.)\n",
    "\n",
    "warning : If you try this code with high frequency, Search engine may ban your ip temporarily (for 5~10 minutes)\n",
    "\n",
    "Refer to : Scroll_cnt=10 >>> about 310 imgs(depending on the searching word)\"\"\"\n",
    "\n",
    "\n",
    "## Install module required\n",
    "#!pip install lxml\n",
    "#!pip install selenium\n",
    "#!pip install bs4\n",
    "\n",
    "\n",
    "## Import modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import time as time\n",
    "import getpass\n",
    "\n",
    "\n",
    "##### Path ######################################################################\n",
    "Chromedriver_PATH = 'c:\\\\chrome_webdriver\\\\chromedriver.exe'  # Chromedriver PATH \n",
    "save_path = 'D:\\\\images\\\\instagram\\\\'  #save_path \n",
    "#################################################################################\n",
    "\n",
    "\n",
    "## get userdata & parameters\n",
    "username = input(\"Input ID : \")  # User ID\n",
    "password = getpass.getpass(\"Input PWD : \")  # User PWD  #getpass : hidden option\n",
    "hashTag_k = input(\"Input HashTag # : \")  # hashTag\n",
    "scroll_cnt = int(input(\"Input scroll_cnt : \"))  #scroll count\n",
    "scrolltime = float(input(\"Input scroll_sleep_second >>> range(5~10) : \"))  #Sleep time \n",
    "hashTag = '#' + hashTag_k\n",
    "\n",
    "\n",
    "## Get driver & open\n",
    "driver = webdriver.Chrome(Chromedriver_PATH)  # Chromedriver PATH \n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "hashLink = '//a[@href=\"/explore/tags/'+hashTag+'/\"]'\n",
    "driver.maximize_window()\n",
    "sleep(3)\n",
    "\n",
    "\n",
    "## insert logindata in \"login div\"\n",
    "element_id = driver.find_element_by_name(\"username\")\n",
    "element_id.send_keys(username)\n",
    "element_password = driver.find_element_by_name(\"password\")\n",
    "element_password.send_keys(password) \n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "## click login botton\n",
    "driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF').click()\n",
    "\n",
    "## input hash tag & push 'Enter'x2\n",
    "time.sleep(10)  #recommand not to change times\n",
    "search = driver.find_element_by_xpath(\"\"\"//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input\"\"\")\n",
    "search.send_keys(hashTag)\n",
    "time.sleep(5)  #recommand not to change times\n",
    "search.send_keys(Keys.ENTER)\n",
    "search.send_keys(Keys.ENTER)\n",
    "time.sleep(10)  #recommand not to change times\n",
    "\n",
    "\n",
    "############## Functions ################################################################################\n",
    "def fetch_list_url():  #parsing src url\n",
    "    imgList = soup.find_all(\"img\", class_=\"FFVAD\")\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])  \n",
    "        except KeyError:\n",
    "            params.append(im[\"srcset\"])\n",
    "    return params\n",
    "\n",
    "\n",
    "def fetch_detail_url():  #save src to local  #changing save_path : Go to the top of this page (Path)\n",
    "    for idx,p in enumerate(params,1):  #enumerate idx option 1 : get start index from 1 (default=0)\n",
    "        urllib.request.urlretrieve(p, save_path + hashTag_k + '_' + str(idx) + \"_instagram\" + \".jpg\")\n",
    "###########################################################################################################    \n",
    "    \n",
    "\n",
    "## Scrolling & Parsing\n",
    "params=[]\n",
    "for i in range(scroll_cnt):\n",
    "    html = driver.page_source  #get source         \n",
    "    soup = BeautifulSoup(html, \"lxml\") \n",
    "    params = fetch_list_url()  #save the img_url to params\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  #scroll\n",
    "    time.sleep(scrolltime)\n",
    "    \n",
    "\n",
    "## Save imgs\n",
    "print('')\n",
    "print(\"Overlap srcs : \", len(params))\n",
    "params=list(dict.fromkeys(params))  #delete overlap  #index URL >> https://m31phy.tistory.com/130\n",
    "fetch_detail_url()  #save img\n",
    "print(\"Non_Overlap srcs : \", len(params))\n",
    "\n",
    "\n",
    "driver.close()  #close browser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ob_1",
   "language": "python",
   "name": "ob_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
